{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ujjwalrai7/Capstone-Project-Online-retail-customer-segmentation/blob/main/Capstone_project_Online_retail_customer_segmentation_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Online Retail Customer Segmentation Project\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised Machine Learning Project\n",
        "##### **Contribution**    - Individual Project By Rai Ujjwal Manoj"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this project was to conduct a comprehensive customer segmentation analysis for an online retail company. The company, an established e-commerce platform, wanted to gain a deeper understanding of its customer base and identify distinct customer segments based on their behaviors, preferences, and characteristics. By segmenting customers, the company aimed to personalize marketing efforts, improve customer targeting, and enhance overall customer experience.\n",
        "\n",
        "The project followed a data-driven approach, utilizing advanced analytical techniques to segment customers. The methodology consisted of the following steps:\n",
        "\n",
        "Data Preprocessing: The collected data underwent preprocessing steps to ensure data quality and consistency. This involved cleaning the data, handling missing values, and transforming variables into suitable formats for analysis.\n",
        "\n",
        "Exploratory Data Analysis: An in-depth exploration of the data was conducted to gain insights into customer behavior and identify patterns. Descriptive statistics, visualizations, and correlation analysis were employed to uncover key trends and relationships within the data.\n",
        "\n",
        "Feature Engineering: To enhance the effectiveness of segmentation, additional features were derived from the existing data. These features were designed to capture specific aspects of customer behavior, such as recency of purchase, frequency of interaction, and monetary value.\n",
        "\n",
        "Segmentation Analysis: Advanced clustering techniques, such as K-means clustering, hierarchical clustering, or Binning models, were applied to segment customers into distinct groups based on their similarities and differences. The appropriate number of segments was determined by evaluating different clustering solutions and selecting the one that provided the most meaningful and actionable insights.\n",
        "\n",
        "Segment Profiling: Each customer segment was carefully profiled and characterized based on their unique attributes. This involved analyzing the key features and behaviors that differentiated one segment from another. The profiles provided a deep understanding of customer preferences, motivations, and needs within each segment."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem at hand is that an online retail company lacks a comprehensive understanding of its diverse customer base. Without proper customer segmentation, the company struggles to effectively target its marketing efforts, personalize customer experiences, and maximize overall customer satisfaction. Therefore, the project aims to address the following\n",
        "problem:\n",
        "\n",
        "Lack of Customer Understanding: The online retail company lacks insights into its customer base, including their behaviors, preferences, and characteristics. As a result, the company is unable to tailor its strategies and offerings to meet the specific needs and expectations of different customer segments.\n",
        "\n",
        "Ineffective Marketing Campaigns: Without proper customer segmentation, the company's marketing campaigns lack relevance and fail to effectively reach the intended audience. The absence of targeted messaging and personalized promotions leads to lower customer engagement and suboptimal conversion rates.\n",
        "\n",
        "Limited Personalization Opportunities: The company struggles to deliver personalized product recommendations, offers, and user experiences to its customers. The absence of segmentation hinders the ability to leverage customer data for personalized marketing, resulting in missed opportunities for cross-selling, upselling, and customer retention.\n",
        "\n",
        "By addressing these problems through a robust customer segmentation analysis, the online retail company can gain a comprehensive understanding of its customer base and effectively tailor its marketing strategies, personalized recommendations, and user experiences. Ultimately, this will lead to improved customer satisfaction, increased customer engagement, higher conversion rates, and enhanced long-term customer loyalty.\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "import warnings\n",
        "from pylab import rcParams\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "df=pd.read_excel(\"/content/drive/MyDrive/Online Retail.xlsx\")"
      ],
      "metadata": {
        "id": "Nmg0f9edi9Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking numbers of unique values in each colums\n",
        "for i in df.columns:\n",
        "  print(i,':' ,df[i].nunique())"
      ],
      "metadata": {
        "id": "uLmtiYPy0t0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(len(df[df.duplicated()]))"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping duplicate rows\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "NrPyFGIU9ZOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar=False);"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is of transnational dataset which contains all the transactions occuring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.\n",
        "* The company mainly sells unique all-occassion gifts.\n",
        "* Many customers of the company are wholesalers.\n",
        "* The dataset contains 541909 rows and 8 columns.\n",
        "* There are 2 columns of datatype float64, 1 column of datatype int64, 4  \n",
        "  columns of datatype object and 1 column of datatype datetime64.\n",
        "* The total number of duplicated values in the dataset: 5268\n",
        "* Missing Data Percentage\n",
        "  CustomerID - 24.93%\n",
        "  Description - 0.27%"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(f'Features: {df.columns.to_list()}')"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### **InvoiceNo**: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "* ### **StockCode**: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "* ### **Description**: Product (item) name. Nominal.\n",
        "* ### **Quantity**: The quantities of each product (item) per transaction. Numeric.\n",
        "* ### **InvoiceDate**: Invoice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "* ### **UnitPrice**: Unit price. Numeric, Product price per unit in sterling.\n",
        "* ### **CustomerID**: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "* ### **Country**: Country name. Nominal, the name of the country where each customer resides."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking numbers of unique values in each colums\n",
        "for i in df.columns:\n",
        "  print(i,':' ,df[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#Extracting year month date & time from Invoice Date column\n",
        "df[\"year\"]  = df[\"InvoiceDate\"].apply(lambda x: x.year)\n",
        "df['Month'] = df['InvoiceDate'].apply(lambda x: x.month_name())\n",
        "df['Day']   = df['InvoiceDate'].apply(lambda x: x.day_name())\n",
        "df[\"hour\"]  = df[\"InvoiceDate\"].apply(lambda x: x.hour)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new feature 'TotalAmount' by multiplying Quantity and UnitPrice\n",
        "df['TotalAmount']= df['UnitPrice'] * df['Quantity']"
      ],
      "metadata": {
        "id": "TIhYe4GbJWnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new feature 'TimeType' based on hours to define whether its Morning,Afternoon or Evening\n",
        "\n",
        "df['TimeType'] = np.where((df[\"hour\"]>5)&(df[\"hour\"]<18), np.where(\n",
        "                           df[\"hour\"]<12, 'Morning','Afternoon'),'Evening')"
      ],
      "metadata": {
        "id": "h3HteAaNJboA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most orders placed are from these countries\n",
        "country_invoice = df.groupby(\"Country\").nunique()[\"InvoiceNo\"].reset_index().sort_values(\"InvoiceNo\",ascending=False)\n",
        "country_invoice.rename(columns={'InvoiceNo': 'Invoice_Count'}, inplace=True)\n",
        "country_invoice.head(10)"
      ],
      "metadata": {
        "id": "QH_AKrr3K3rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most customers are from these countries\n",
        "country_cust = df.groupby(\"Country\").nunique()[\"CustomerID\"].reset_index().sort_values(\"CustomerID\",ascending=False)\n",
        "country_cust.rename(columns={'CustomerID': 'Customer_Count'}, inplace=True)\n",
        "country_cust.head()"
      ],
      "metadata": {
        "id": "McujRwNIK_vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Countrywise average item purchases\n",
        "country_quantity = df.groupby(\"Country\").mean()[\"Quantity\"].reset_index().sort_values(\"Quantity\",ascending=False)\n",
        "country_quantity.rename(columns={'Quantity': 'Average_Quantity'}, inplace=True)\n",
        "country_quantity.head()"
      ],
      "metadata": {
        "id": "WVGjywjDLIaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quantity wise item purchases\n",
        "product_quantity = df.groupby(\"Description\").sum()[\"Quantity\"].reset_index().sort_values(\"Quantity\",ascending=False)\n",
        "product_quantity.head()"
      ],
      "metadata": {
        "id": "gcEOPiQCLTT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amount wise item purchases\n",
        "product_price = df.groupby(\"Description\").sum()[\"TotalAmount\"].reset_index().sort_values(\"TotalAmount\",ascending=False)\n",
        "product_price.head()"
      ],
      "metadata": {
        "id": "_y_-Hm5MMWfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StockCode_df=df['StockCode'].value_counts().reset_index()\n",
        "StockCode_df.rename(columns={'index': 'StockCode_Name'}, inplace=True)\n",
        "StockCode_df.rename(columns={'StockCode': 'Count'}, inplace=True)\n",
        "StockCode_df.head()"
      ],
      "metadata": {
        "id": "CxiB_N4ZPmIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df=df['hour'].value_counts().reset_index()\n",
        "hour_df.rename(columns={'index': 'Hour_Name'}, inplace=True)\n",
        "hour_df.rename(columns={'hour': 'Count'}, inplace=True)\n",
        "hour_df"
      ],
      "metadata": {
        "id": "LcFcG-tFb_Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "month_df=df['Month'].value_counts().reset_index()\n",
        "month_df.rename(columns={'index': 'Month_Name'}, inplace=True)\n",
        "month_df.rename(columns={'Month': 'Count'}, inplace=True)\n",
        "month_df"
      ],
      "metadata": {
        "id": "5jqjj-gbcmwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_df=df['Day'].value_counts().reset_index()\n",
        "day_df.rename(columns={'index': 'Day_Name'}, inplace=True)\n",
        "day_df.rename(columns={'Day': 'Count'}, inplace=True)\n",
        "day_df"
      ],
      "metadata": {
        "id": "8IQ-KzXr_Es4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Most Customers are from United Kingdom. Considerable number of customers are also from Germany, France, EIRE and Spain. Whereas Saudi Arabia, Bahrain, Czech Republic, Brazil and Lithuania has least number of customers\n",
        "2. There are no orders placed on Saturdays. Looks like it's a non working day for the retailer.\n",
        "3. Most of the customers have purchased the gifts in the month of November, October, December and September. Less number of customers have purchased the gifts in the month of April, January and February.\n",
        "4. Most of the customers have purchased the items in Afternoon, moderate numbers of customers have purchased the items in Morning and the least in Evening.\n",
        "5. WHITE HANGING HEART T-LIGHT HOLDER, REGENCY CAKESTAND 3 TIER, JUMBO BAG RED RETROSPOT are the most ordered products"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 Quantity wise most items purchases"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# quantity wise most item purchases\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"Product with High quantity orders\")\n",
        "sns.barplot(data=product_quantity.head(10),x=\"Description\",y=\"Quantity\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise quantity wise purchases of products"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "world war 2 gliders, Jumbo bag , Popcorn etc are the items purchased in maximum quantity."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it would help the management to decide the incentives on the products such as discount wether to keep or extend or detain on such high selling items."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Country wise visualisation of total invoices."
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Visualizing top 10 countries based on total invoices\n",
        "plt.figure(figsize=(20,5),dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"Most orders placed are from these countries\")\n",
        "sns.barplot(data=country_invoice.head(10),x=\"Country\",y=\"Invoice_Count\")"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Visualize top 10 countries based on total invoices"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "United Kingdom is making most of the purchases as compared to other countries\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 Visualizing top 10 countries based on average item purchases"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"High quantity orders are from these countries\")\n",
        "sns.barplot(data=country_quantity.head(10),x=\"Country\",y=\"Average_Quantity\")"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " To Visualize top 10 countries based on average item purchases"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orders with mass quantity are placed by the customers from Netherlands"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4  Visualising the top stocks"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Top 5 Stock Name')\n",
        "sns.barplot(x='StockCode_Name',y='Count',data=StockCode_df[:5])"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise the top stocks."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be generated are Top 5 Stock name based on selling are :\n",
        "\n",
        "1)85123A\n",
        "\n",
        "2)22423\n",
        "\n",
        "3)85099B\n",
        "\n",
        "4)47566\n",
        "\n",
        "5)20725\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5    Day wise visualisation of customer count"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Day')\n",
        "sns.barplot(x='Day_Name',y='Count',data=day_df)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise the daily customer count.\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the customers have purches the items in Thursday ,Wednesday and Tuesday also it can be said that as there is no data for saturday the store might be closed on saturday\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact.\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6  Monthly Analysis of customer count.\n"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Month wise customer purchase\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Month')\n",
        "sns.barplot(x='Month_Name',y='Count',data=month_df)"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise Month wise customer purchase."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most numbers of customers have purchased the gifts in the month of November,December October and  September\n",
        "\n",
        "less numbers of customers have purchased the gifts in the month of April ,January and February"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 Hourly analysis of customer purchases"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code.\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Hour')\n",
        "sns.barplot(x='Hour_Name',y='Count',data=hour_df)"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise the hourly customer purchases."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this graph we can see that from 11:00 am to 4:00 pm most of the customers have purchased the item."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 Time_type wise analysis of customer purchases."
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Time_type')\n",
        "sns.countplot(x='TimeType',data=df)"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise at what phase of time there is maximum purchases."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the customers have purchased the items in Aftrnoon ,moderate numbers of customers have purchased the items in Morning and least numbers of customers have purchased the items in evening"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 Distribution analysis."
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Visualizing the distributions.\n",
        "target = ['Quantity','UnitPrice','TotalAmount']\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "for n,col in enumerate(target):\n",
        "  plt.subplot(1, 3, n+1)\n",
        "  sns.distplot(df[col])\n",
        "  plt.title(col.title())\n",
        "  plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise the distribution of various features."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. It shows a positively skewed distribution because most of the values are clustered around the left side of the distribution while the right tail of the distribution is longer, which means mean>median>mode2. For symmetric graph mean=median=mode."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 Year wise analysis."
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Year')\n",
        "sns.countplot(x='year',data=df)"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ti visualise the yearly pattern of customer purchases."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the data is from the year 2011 and very less purchases belongs to 2010."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights would help creating a positive business impact.\n",
        "\n"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        " ## Correlation\n",
        "plt.figure(figsize=(20,12))\n",
        "correlation = df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses. The range of correlation is [-1,1].\n",
        "\n",
        "Thus to know the correlation between all the variables along with the correlation coeficients, i used correlation heatmap."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "None of the features are highly correlated except total amount which is formed from quantity."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "# Pair Plot visualization code\n",
        "sns.pairplot(df ,hue=\"CustomerID\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair plot is used to understand the best set of features to explain a relationship between two variables or to form the most separated clusters. It also helps to form some simple classification models by drawing some simple lines or make linear separation in our data-set.\n",
        "\n",
        "Thus, I used pair plot to analyse the patterns of data and realationship between the features. It's exactly same as the correlation map but here you will get the graphical representation."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above chart depicts the correlation of various labels with respect to customerID around."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#missing data counts and percentage\n",
        "\n",
        "missing = df.columns[df.isnull().any()].tolist()\n",
        "missing\n",
        "\n",
        "print('Missing Data count')\n",
        "print(df[missing].isnull().sum().sort_values(ascending=False))\n",
        "\n",
        "print('++'*12)\n",
        "print('Missing Data Percentage')\n",
        "print(round(df[missing].isnull().sum().sort_values(ascending=False)/len(df)*100,2))"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the rows with null values\n",
        "df.dropna(subset=['CustomerID'],inplace=True)"
      ],
      "metadata": {
        "id": "Fh2SERi1pPYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.93% of items purchases are not assigned to any customer\n",
        "Hence there is no use of having the data with no customer assignment.\n",
        "Because we can't form clusters without CustomerID so we will delete them from dataset."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "TPY2Wso8rOUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking duplicates\n",
        "print(len(df[df.duplicated()]))"
      ],
      "metadata": {
        "id": "8gWpmb0nsmJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null counts and datatype in each column\n",
        "df.info()"
      ],
      "metadata": {
        "id": "SQTMeOnss9Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
        "cancellations = df[df['InvoiceNo'].str.contains('C')]\n",
        "cancellations.shape"
      ],
      "metadata": {
        "id": "oHDpl5pxtXba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping cancellations from the main dataframe\n",
        "df = df[~df['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "qMu_jY16tc0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "EC2cP1uQtfDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not needed in this case."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not needed in this case."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RFM Modelling**"
      ],
      "metadata": {
        "id": "3dxLcOoAvvIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***RFM (Recency, Frequency, Monetary) modeling is a statistical technique used in marketing and customer relationship management to analyze customer behavior and determine the value of each customer to a business. It involves analyzing the transactional data of customers and grouping them based on their buying behavior.***\n",
        "\n",
        "***Recency refers to how recently a customer has made a purchase from the business. Frequency refers to how often a customer makes purchases, and Monetary refers to how much a customer spends on purchases. These three factors are used to assign scores to each customer, which are then used to segment them into different groups.***\n",
        "\n",
        "***In general, customers who have made recent purchases, purchase frequently, and spend more money are considered to be more valuable to the business than those who have not made a purchase recently, purchase infrequently, and spend less money. RFM modeling helps businesses identify their most valuable customers and tailor their marketing efforts accordingly, such as by offering personalized promotions or improving customer service.***\n",
        "\n",
        "***RFM modeling can be performed using various statistical techniques, such as clustering or decision tree analysis. However, it requires accurate and up-to-date data on customer transactions, and the results may need to be validated and updated periodically to reflect changes in customer behavior.***"
      ],
      "metadata": {
        "id": "Jfj7RnFRvxov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Adding 1 day to the Last Invoice date to set as Latest date for reference\n",
        "LatestDate = df[\"InvoiceDate\"].max() + pd.DateOffset(days=1)\n",
        "\n",
        "# Creating a new dataframe to calculate Recency, Frequency and Monetary scores for each customer\n",
        "rfm = df.groupby('CustomerID').agg({'InvoiceDate': lambda x: (LatestDate - x.max()).days,\n",
        "                                    'InvoiceNo': lambda x: len(x), 'TotalAmount': lambda x: x.sum()})\n",
        "\n",
        "# Renaming the columns\n",
        "rfm.rename(columns={'InvoiceDate': 'Recency', 'InvoiceNo': 'Frequency',\n",
        "                    'TotalAmount': 'Monetary'}, inplace=True)\n",
        "\n",
        "# Checking top 5 rows\n",
        "rfm.reset_index().head()\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating R, F and M scores by splitting Recency, Frequency\tand Monetary based on quantiles\n",
        "rfm['R'] = pd.qcut(rfm['Recency'], q=4, labels=[4,3,2,1]).astype(int)\n",
        "rfm['F'] = pd.qcut(rfm['Frequency'], q=4, labels=[1,2,3,4]).astype(int)\n",
        "rfm['M'] = pd.qcut(rfm['Monetary'], q=4, labels=[1,2,3,4]).astype(int)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the RFM Group for each customer by combining the factors R,Fand M\n",
        "rfm['RFM'] = 100*rfm['R'] + 10*rfm['F'] + rfm['M']\n",
        "\n",
        "# Finding the RFM Score for each customer by adding the factors R,Fand M\n",
        "rfm['RFM_Score'] = rfm['R'] + rfm['F'] + rfm['M']"
      ],
      "metadata": {
        "id": "WL1yrgaYwmys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***RFM (Recency, Frequency, Monetary) modeling is a statistical technique used in marketing and customer relationship management to analyze customer behavior and determine the value of each customer to a business. It involves analyzing the transactional data of customers and grouping them based on their buying behavior.***"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.head()"
      ],
      "metadata": {
        "id": "5jjGb49h0oJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Customers: \",len(rfm[rfm['RFM']==444]))\n",
        "print('Loyal Customers: ',len(rfm[rfm['F']==4]))\n",
        "print(\"Big Spenders: \",len(rfm[rfm['M']==4]))\n",
        "print('Almost Lost: ', len(rfm[rfm['RFM']==244]))\n",
        "print('Lost Customers: ',len(rfm[rfm['RFM']==144]))\n",
        "print('Lost Cheap Customers: ',len(rfm[rfm['RFM']==111]))"
      ],
      "metadata": {
        "id": "rddPd_xcG4N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interpretation:**\n",
        "***1. If the RFM of any customer is 444. His Recency is good, frequency is more and Monetary is more. So, he is the best customer.***</br>\n",
        "***2. If the RFM of any customer is 111. His Recency is low, frequency is low and Monetary is low. So, he is the churning customer.***</br>\n",
        "***3. If the RFM of any customer is 144. He purchased a long time ago but buys frequently and spends more. And so on.***</br>\n",
        "***4. Like this we can come up with number of segments for all combinations of R,F and M base on our usecase. Higher the RFM score, more valuable the customer is.***"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the distributions.\n",
        "target = ['Quantity','UnitPrice','TotalAmount']\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "for n,col in enumerate(target):\n",
        "  plt.subplot(1, 3, n+1)\n",
        "  sns.distplot(df[col])\n",
        "  plt.title(col.title())\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "V0i3t6rkuaD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. It shows a positively skewed distribution because most of the values are clustered around the left side of the distribution while the right tail of the distribution is longer, which means mean>median>mode\n",
        "2. For symmetric graph mean=median=mode."
      ],
      "metadata": {
        "id": "tNAC96nzu4gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "target = ['Quantity']\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "for n,col in enumerate(target):\n",
        "  plt.subplot(1, 3, n+1)\n",
        "  sns.distplot(np.log(df[col]))\n",
        "  plt.title(col.title())\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling the zeroes in the dataframe to avoid error in transformations\n",
        "rfm.replace(0.0,1,inplace=True)\n",
        "\n",
        "# Applying Log transformation on columns for smoothening the distribution\n",
        "rfm['Recency_Log']   = rfm['Recency'].apply(np.log)\n",
        "rfm['Frequency_Log'] = rfm['Frequency'].apply(np.log)\n",
        "rfm['Monetary_Log']  = rfm['Monetary'].apply(np.log)\n",
        "rfm.head()"
      ],
      "metadata": {
        "id": "brNILJrFyF9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the distributions before and after log transformation.\n",
        "target = ['Recency', 'Frequency',\t'Monetary', 'Recency_Log', 'Frequency_Log', 'Monetary_Log']\n",
        "plt.figure(figsize=(20,10), dpi=90)\n",
        "for n,col in enumerate(target):\n",
        "  plt.subplot(2, 3, n+1)\n",
        "  sns.distplot(rfm[col])\n",
        "  plt.title(col.title())\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "bcWr5WULyNhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Observations:**\n",
        "***1. Earlier the distributions of Recency, Frequency and Monetary columns were positively skewed but after applying log transformation, the distributions appear to be symmetrical and normally distributed.***\n",
        "***2. It will be more suitable to use the transformed features for better visualisation of clusters.***"
      ],
      "metadata": {
        "id": "bpJLztD3ycLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the correlations among features.\n",
        "target = ['Recency_Log','Frequency_Log','Monetary_Log','RFM','RFM_Score']\n",
        "plt.figure(figsize = (8, 4), dpi=150)\n",
        "sns.heatmap(abs(rfm[target].corr()), annot=True, cmap='coolwarm')\n",
        "plt.title('RFM Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jyyF9vIsykgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset doesnot need any dimensionality reduction.\n",
        "\n",
        "Dimensionality reduction is a technique that is used to reduce the number of features in a dataset. It is often used when the number of features is very large, as this can lead to problems such as overfitting and slow computation. There are a variety of techniques that can be used for dimensionality reduction, such as principal component analysis (PCA) and singular value decomposition (SVD).\n",
        "\n",
        "There are several reasons why dimensionality reduction might be useful. One reason is that it can help to reduce the size of a dataset, which can be particularly useful when the dataset is very large. It can also help to improve the performance of machine learning models by reducing the number of features that the model has to consider, which can lead to faster computation and better generalization to new data.\n",
        "\n",
        "Another reason to use dimensionality reduction is to reduce the curse of dimensionality, which refers to the fact that as the number of dimensions increases, the volume of the space increases exponentially. This can lead to problems such as the nearest neighbor search becoming less effective, as the distances between points become much larger. Dimensionality reduction can help to reduce the curse of dimensionality by reducing the number of dimensions in the data.\n",
        "\n",
        "Finally, dimensionality reduction can also be useful for visualizing high-dimensional data. It can be difficult to visualize data in more than three dimensions, so reducing the number of dimensions can make it easier to understand the patterns in the data."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not Required in this case as it is an unsupervised machine learning project."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imbalanced dataset is relevant primarily in the context of supervised machine learning involving two or more classes.\n",
        "\n",
        "Imbalance means that the number of data points available for different the classes is different: If there are two classes, then balanced data would mean 50% points for each of the class. For most machine learning techniques, little imbalance is not a problem. So, if there are 60% points for one class and 40% for the other class, it should not cause any significant performance degradation. Only when the class imbalance is high, e.g. 90% points for one class and 10% for the other, standard optimization criteria or performance measures may not be as effective and would need modification.\n",
        "\n",
        "In our case it is not required and imbalanced."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.head()"
      ],
      "metadata": {
        "id": "pUbSlq5k5J2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig=plt.figure(figsize=(15,10))\n",
        "plt.title('3d visualization of Recency Frequency and Monetary')\n",
        "ax=fig.add_subplot(111,projection='3d')\n",
        "xs=rfm.Recency_Log\n",
        "ys=rfm.Frequency_Log\n",
        "zs=rfm.Monetary_Log\n",
        "ax.scatter(xs,ys,zs,s=5)\n",
        "ax.set_xlabel('Recency')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_zlabel('Monetary value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tYsv7V5C5B9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1    ****K-Means Clustering****"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying Silhouette  Method on Recency ,Frequency and Monetary"
      ],
      "metadata": {
        "id": "HHwnU9WQ4j3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "APmdy0JX6KI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vector=['Recency_Log','Frequency_Log','Monetary_Log']\n",
        "X_features=rfm[feature_vector].values\n",
        "scaler=preprocessing.StandardScaler()\n",
        "X=scaler.fit_transform(X_features)"
      ],
      "metadata": {
        "id": "HbTDuASd443q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFNN2SaYxji2"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "range_n_clusters = [2,3,4,5,6,7,8]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Create a subplot with 1 row and 2 columns\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    # The 1st subplot is the silhouette plot\n",
        "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "    # lie within [-0.1, 1]\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "    # plots of individual clusters, to demarcate them clearly.\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Initialize the clusterer with n_clusters value and a random generator\n",
        "    # seed of 10 for reproducibility.\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
        "    cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "    # The silhouette_score gives the average value for all the samples.\n",
        "    # This gives a perspective into the density and separation of the formed\n",
        "    # clusters\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\"For n_clusters =\", n_clusters,\n",
        "          \"The average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        # Aggregate the silhouette scores for samples belonging to\n",
        "        # cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    # 2nd Plot showing the actual clusters formed\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) /n_clusters)\n",
        "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "    # Labeling the clusters\n",
        "    centers = clusterer.cluster_centers_\n",
        "    # Draw white circles at cluster centers\n",
        "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  We can see that the maximum sihouette score is when no. of clusters is 2 ###"
      ],
      "metadata": {
        "id": "XDdJfUQ6-vod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Applying Elbow Method on Recency ,Frequency and Monetary**"
      ],
      "metadata": {
        "id": "eOL8ZFXk9yW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "sum_of_sq_dist = {}\n",
        "for k in range(1,15):\n",
        "    km = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n",
        "    km = km.fit(X)\n",
        "    sum_of_sq_dist[k] = km.inertia_\n",
        "\n",
        "#Plot the graph for the sum of square distance values and Number of Clusters\n",
        "sns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()))\n",
        "plt.xlabel('Number of Clusters(k)')\n",
        "plt.ylabel('Sum of Square Distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "peRt8rtH9wji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From the above elbow curve we can see that optimal no of clusters would be 2 or 3 ##"
      ],
      "metadata": {
        "id": "t12f5HhD_usy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From both elbow curve and silhouette score considering 2 as optimal no. of clusters and implementing K-Means ##"
      ],
      "metadata": {
        "id": "LV2CH7hNBx7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means Implementation"
      ],
      "metadata": {
        "id": "NGgsQtiXBHdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "y_kmeans= kmeans.predict(X)"
      ],
      "metadata": {
        "id": "xhQz_3Rn9dzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.title('customer segmentation based on    Recency ,Frequency and Monetary')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='RdYlBu')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='yellow', s=200, alpha=0.5)"
      ],
      "metadata": {
        "id": "R4oPNeq99gtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Perform K-Mean Clustering or build the K-Means clustering model\n",
        "KMean_clust = KMeans(n_clusters= 2, init= 'k-means++', max_iter= 1000)\n",
        "KMean_clust.fit(X)\n",
        "\n",
        "#Find the clusters for the observation given in the dataset\n",
        "rfm['Cluster'] = KMean_clust.labels_\n",
        "rfm.head(10)"
      ],
      "metadata": {
        "id": "FC5SHJrWBWF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func(row):\n",
        "    if row[\"Cluster\"]==0:\n",
        "        return 'Major Customers'\n",
        "    elif row[\"Cluster\"]==1:\n",
        "        return 'At Risk'\n",
        "    else:\n",
        "        return 'Average Standing Customers'"
      ],
      "metadata": {
        "id": "dxJjM9reLnBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm['group']=rfm.apply(func, axis=1)\n",
        "rfm"
      ],
      "metadata": {
        "id": "seG5NTKyL201"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2- ***Hierarchical Clustering***"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dendogram to find the optimal number of clusters**"
      ],
      "metadata": {
        "id": "YZwdBXE92_eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram,linkage\n",
        "# Clustering alorithms\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN"
      ],
      "metadata": {
        "id": "uc8Oz1FM4OlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the Dendogram to Decide the number of clusters\n",
        "plt.figure(figsize=(15,12), dpi=90)                         # Setting the figure size\n",
        "dendrogram(linkage(X, method='ward'), color_threshold=50)   # using ward linkage method to differ similarities\n",
        "plt.title('Dendrogram')                                     # Setting the title\n",
        "plt.xlabel('Customers')                                     # Setting the x label\n",
        "plt.ylabel('Euclidean Distances')                           # Setting y label\n",
        "plt.axhline(y=70, color='black', linestyle='--')            # Setting the axis line for y=70\n",
        "plt.axhline(y=50, color='black', linestyle='--')            # Setting the axis line for y=50\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wn5cRWVh4VWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From both Dendogram considering 2 as optimal no. of clusters and implementing Hierarchical Clustering ##"
      ],
      "metadata": {
        "id": "jRXvxLrBNMkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering to the mall dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
        "y_hc = hc.fit_predict(X)"
      ],
      "metadata": {
        "id": "kk7CaQoiAHt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the clusters (two dimensions only)\n",
        "plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = '0')\n",
        "plt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = '1')\n",
        "#plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = '2')\n",
        "\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('RFM')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dqLrmp4AnQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 DBSCAN (Density-Based Spatial Clustering of Applications with Noise)"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBSCAN is a density-based clustering algorithm that groups data points based on their density in the feature space. It identifies clusters as dense regions separated by areas of lower density and is robust to noise and outliers. It doesn't require specifying the number of clusters in advance. Its parameters include the radius (Eps) and minimum number of points (MinPts) to form a core point."
      ],
      "metadata": {
        "id": "Lf5V4LclOCwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Create and fit the DBSCAN model\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=15)\n",
        "dbscan.fit(X)\n",
        "\n",
        "# Plot the results\n",
        "plt.scatter(X[:,0], X[:,1], c=dbscan.labels_, cmap='rainbow')\n",
        "plt.title('DBSCAN Clustering')\n",
        "plt.xlabel('RFM')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OE3EVy0pOLDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The chart used is a scatter plot, which is a suitable choice for visualizing the clustering results of DBSCAN. The x and y axes represent the two features of the dataset, and the points are colored based on their assigned cluster labels.\n",
        "\n",
        "* The insights gained from the chart include identifying the clusters formed by the DBSCAN algorithm and their density. The points that are closer to each other are assigned to the same cluster, and the outliers or noise points are labeled as -1. By observing the distribution of the points and the density of the clusters, we can understand the structure and characteristics of the data, and potentially find any patterns or anomalies.\n",
        "\n",
        "* The gained insights can help in creating a positive business impact by identifying groups of similar data points, which can aid in targeting specific segments of customers or optimizing operational processes."
      ],
      "metadata": {
        "id": "QpjXsAFzOpCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "yCI3yUu5O-_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Initialize the table with specified column names\n",
        "myTable = PrettyTable(['SL No.', \"Model_Name\", 'Data', \"Optimal_Number_of_cluster\"])\n",
        "\n",
        "# Add rows to the table\n",
        "myTable.add_row(['1', \"K-Means with silhouette_score\", \"RFM\", \"2\"])\n",
        "myTable.add_row(['2', \"K-Means with Elbow method\", \"RFM\", \"2\"])\n",
        "myTable.add_row(['3', \"Hierarchical clustering\", \"RFM\", \"2\"])\n",
        "myTable.add_row(['4',\"DBSCAN \", \"RFM\", \"3\"])\n",
        "\n",
        "# Print the table\n",
        "print(myTable)"
      ],
      "metadata": {
        "id": "mkNgmGqzO9vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA**\n",
        "\n",
        "* Null values and duplicates were removed from the dataset before applying clustering.\n",
        "\n",
        "* Top customer IDs were found to be 17841.0, 14911.0, 14096.0, 12748.0, and 14606.0.\n",
        "\n",
        "* The top five countries based on the percentage of total orders were the United Kingdom (88.95%), Germany (2.33%), France (1.84%), Ireland (1.84%), and Spain (0.62%).\n",
        "\n",
        "* The top five products purchased based on frequency were White Hanging Heart T-Light Holder, Regency Cakestand 3 Tier, Jumbo Bag Red Retrospot, Party Bunting, and Assorted Colour Bird Ornament.\n",
        "\n",
        "* The top stock codes based on count values were 85123A, 22423, 85099B, 47566, and 84879.\n",
        "\n",
        "* New columns were created using InvoiceDate, such as Year, Month, Day, Hour, Month_Num, and Day_Num.\n",
        "\n",
        "* The total amount of each order was calculated using the product of unit price and quantity.\n",
        "\n",
        "* The months of November, October, December, September, and May generated the most business.\n",
        "\n",
        "* The most popular purchasing days were Thursday, Wednesday, Tuesday, Monday, Saturday, and Friday.\n",
        "\n",
        "* Most customers made purchases between 10:00 A.M. and 2:00 P.M.\n",
        "\n",
        "* The top time duration for purchasing was found to be afternoon, followed by morning and evening.\n",
        "\n",
        "**Algorithm**\n",
        "\n",
        "* RFM (Recency, Frequency, and Monetary) dataframe helps in solving problems in a particular order, making it easy to recommend and display new products to selected customers.\n",
        "\n",
        "* Different clustering algorithms were applied to the dataset, including: Clustering on Recency, Frequency & Monetary (RFM) with 2 clusters.\n",
        "\n",
        "1. K-Means with Silhouette_score\n",
        "2. K-Means with Elbow Method\n",
        "3. Hierarchical Clustering\n",
        "4. DBSCAN"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}